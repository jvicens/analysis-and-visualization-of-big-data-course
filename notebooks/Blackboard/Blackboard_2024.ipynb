{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd001590-1ed7-477a-b546-3df6dd390c01",
   "metadata": {},
   "source": [
    "# Blackboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942996c-0edb-45db-84b5-2ccefe77015b",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ab72b1-edae-4447-8f38-5e30e8241b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian.vicens/.envs/ub/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from os.path import dirname, join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "from bokeh.io import show, output_notebook, curdoc\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import ColumnDataSource, Div, Select, Slider, TextInput, AutocompleteInput, Button, Jitter, WheelZoomTool, BoxZoomTool, ResetTool, PanTool, TapTool, NumeralTickFormatter\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import cumsum\n",
    "\n",
    "from io import StringIO\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9726927-69ac-40bc-85c7-34bc9d41c5bb",
   "metadata": {},
   "source": [
    "### Logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c06f675-6172-45f1-86fc-fec67fac327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a warning\n",
      "This is an error\n"
     ]
    }
   ],
   "source": [
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create a handler that writes log messages to stdout\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create a formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "# logger.addHandler(handler)\n",
    "\n",
    "# Test the logger\n",
    "logger.debug(\"This is a debug\")\n",
    "logger.info(\"This is a info\")\n",
    "logger.warning(\"This is a warning\")\n",
    "logger.error(\"This is an error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8deee9-19da-4276-a82a-9704261caffc",
   "metadata": {},
   "source": [
    "### Data from API\n",
    "\n",
    "Loading CSV data from an API with pagination support. The `load_csv_from_api` function allows for efficient retrieval of large datasets by fetching data in chunks and supporting a maximum row limit. It handles pagination, combines the data into a single DataFrame, and saves the result as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d26933b-2485-40e1-bc7c-9d70e14a3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_from_api(url, chunk_size=1000, max_rows=None):\n",
    "    \"\"\"\n",
    "    Loads CSV data from an API with pagination support.\n",
    "\n",
    "    This function retrieves data from the specified API URL in chunks, combines them\n",
    "    into a single DataFrame, and optionally limits the total number of rows fetched.\n",
    "    The resulting dataset is saved as a CSV file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The base URL of the API endpoint.\n",
    "        chunk_size (int, optional): The number of rows to fetch in each API call. Defaults to 1000.\n",
    "        max_rows (int, optional): The maximum number of rows to fetch in total. Defaults to None (no limit).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The complete dataset fetched from the API.\n",
    "\n",
    "    Raises:\n",
    "        requests.RequestException: If there's an error in making the API request.\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    all_data = []\n",
    "    total_rows_fetched = 0\n",
    "    \n",
    "    logger.info(f\"Starting data retrieval from {url}\")\n",
    "    logger.info(f\"Chunk size: {chunk_size}, Max rows: {max_rows if max_rows else 'No limit'}\")\n",
    "    \n",
    "    while True:\n",
    "        # Construct the URL with offset and limit parameters\n",
    "        paginated_url = f\"{url}?$offset={offset}&$limit={chunk_size}\"\n",
    "        \n",
    "        # Make the API request\n",
    "        response = requests.get(paginated_url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Convert the response content to a pandas DataFrame\n",
    "            chunk = pd.read_csv(StringIO(response.text))\n",
    "            \n",
    "            # If the chunk is empty, we've reached the end of the data\n",
    "            if chunk.empty:\n",
    "                logger.info(\"Received empty chunk. Ending pagination.\")\n",
    "                break\n",
    "            \n",
    "            # Append the chunk to our list of DataFrames\n",
    "            all_data.append(chunk)\n",
    "            \n",
    "            # Update total rows fetched\n",
    "            total_rows_fetched += len(chunk)\n",
    "            logger.info(f\"Fetched {len(chunk)} rows. Total rows so far: {total_rows_fetched}\")\n",
    "            \n",
    "            # Increment the offset for the next request\n",
    "            offset += chunk_size\n",
    "            \n",
    "            # If we've reached the maximum number of rows, stop\n",
    "            if max_rows and total_rows_fetched >= max_rows:\n",
    "                logger.info(f\"Reached or exceeded max rows ({max_rows}). Stopping pagination.\")\n",
    "                break\n",
    "        else:\n",
    "            logger.error(f\"Error fetching data: HTTP {response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    # Combine all chunks into a single DataFrame\n",
    "    logger.info(\"Combining all fetched data into a single DataFrame\")\n",
    "    full_dataset = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # If max_rows was specified, trim the dataset\n",
    "    if max_rows and len(full_dataset) > max_rows:\n",
    "        logger.info(f\"Trimming dataset to {max_rows} rows\")\n",
    "        full_dataset = full_dataset.head(max_rows)\n",
    "    \n",
    "    logger.info(f\"Final dataset size: {len(full_dataset)} rows\")\n",
    "    \n",
    "    # Save the dataset as a CSV file\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    dirname = ''\n",
    "    filename = f\"Estadistica_places_{current_date}.csv\"\n",
    "    full_dataset.to_csv(dirname + filename, index=False)\n",
    "    logger.info(f\"Dataset saved to {filename}\")    \n",
    "    \n",
    "    return full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df3b0681-8989-4ff8-9104-f9430188ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_from_api(url, chunk_size=1000, format='json', filters=None, max_rows=None):\n",
    "    \"\"\"\n",
    "    Loads JSON data from an API with pagination support.\n",
    "\n",
    "    This function retrieves data from the specified API URL in chunks, combines them\n",
    "    into a single DataFrame, and optionally limits the total number of rows fetched.\n",
    "    The resulting dataset is saved as a CSV file.\n",
    "\n",
    "    Args:\n",
    "        url (str): The base URL of the API endpoint.\n",
    "        chunk_size (int, optional): The number of rows to fetch in each API call. Defaults to 1000.\n",
    "        max_rows (int, optional): The maximum number of rows to fetch in total. Defaults to None (no limit).\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The complete dataset fetched from the API.\n",
    "\n",
    "    Raises:\n",
    "        requests.RequestException: If there's an error in making the API request.\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "    all_data = []\n",
    "    total_rows_fetched = 0\n",
    "    \n",
    "    logger.info(f\"Starting data retrieval from {url}\")\n",
    "    logger.info(f\"Chunk size: {chunk_size}, Max rows: {max_rows if max_rows else 'No limit'}\")\n",
    "    \n",
    "    while True:\n",
    "        # Construct the URL with offset and limit parameters\n",
    "        paginated_url = f\"{url}?$offset={offset}&$limit={chunk_size}\"\n",
    "\n",
    "        # Make the API request\n",
    "        response = requests.get(paginated_url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Convert the response content to a pandas DataFrame\n",
    "            chunk = pd.json_normalize(response.json())\n",
    "            \n",
    "            # If the chunk is empty, we've reached the end of the data\n",
    "            if chunk.empty:\n",
    "                logger.info(\"Received empty chunk. Ending pagination.\")\n",
    "                break\n",
    "            \n",
    "            # Append the chunk to our list of DataFrames\n",
    "            all_data.append(chunk)\n",
    "            logger.info(\"Data size: \"+ str(len(all_data)))\n",
    "            # Update total rows fetched\n",
    "            total_rows_fetched += len(chunk)\n",
    "            logger.info(f\"Fetched {len(chunk)} rows. Total rows so far: {total_rows_fetched}\")\n",
    "            # Increment the offset for the next request\n",
    "            offset += chunk_size\n",
    "            \n",
    "            # If we've reached the maximum number of rows, stop\n",
    "            if max_rows and total_rows_fetched >= max_rows:\n",
    "                logger.info(f\"Reached or exceeded max rows ({max_rows}). Stopping pagination.\")\n",
    "                break\n",
    "        else:\n",
    "            logger.error(f\"Error fetching data: HTTP {response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    # Combine all chunks into a single DataFrame\n",
    "    logger.info(\"Combining all fetched data into a single DataFrame\")\n",
    "    full_dataset = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # If max_rows was specified, trim the dataset\n",
    "    if max_rows and len(full_dataset) > max_rows:\n",
    "        logger.info(f\"Trimming dataset to {max_rows} rows\")\n",
    "        full_dataset = full_dataset.head(max_rows)\n",
    "    \n",
    "    logger.info(f\"Final dataset size: {len(full_dataset)} rows\")\n",
    "    \n",
    "    # Save the dataset as a CSV file\n",
    "    current_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "    dirname = ''\n",
    "    filename = f\"data_{current_date}.csv\"\n",
    "    full_dataset.to_csv(dirname + filename, index=False)\n",
    "    logger.info(f\"Dataset saved to {filename}\")    \n",
    "    \n",
    "    return full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8852c14-d755-4de8-a034-5a99755f3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting data retrieval from https://analisi.transparenciacatalunya.cat/resource/nzvn-apee.json\n",
      "INFO:__main__:Chunk size: 10, Max rows: 100\n",
      "INFO:__main__:Data size: 1\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 10\n",
      "INFO:__main__:Data size: 2\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 20\n",
      "INFO:__main__:Data size: 3\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 30\n",
      "INFO:__main__:Data size: 4\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 40\n",
      "INFO:__main__:Data size: 5\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 50\n",
      "INFO:__main__:Data size: 6\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 60\n",
      "INFO:__main__:Data size: 7\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 70\n",
      "INFO:__main__:Data size: 8\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 80\n",
      "INFO:__main__:Data size: 9\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 90\n",
      "INFO:__main__:Data size: 10\n",
      "INFO:__main__:Fetched 10 rows. Total rows so far: 100\n",
      "INFO:__main__:Reached or exceeded max rows (100). Stopping pagination.\n",
      "INFO:__main__:Combining all fetched data into a single DataFrame\n",
      "INFO:__main__:Final dataset size: 100 rows\n",
      "INFO:__main__:Dataset saved to data_20241114.csv\n",
      "INFO:__main__:Loaded 100 rows of data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>codi_estacio</th>\n",
       "      <th>codi_variable</th>\n",
       "      <th>data_lectura</th>\n",
       "      <th>valor_lectura</th>\n",
       "      <th>codi_estat</th>\n",
       "      <th>codi_base</th>\n",
       "      <th>data_extrem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VC462405221230</td>\n",
       "      <td>VC</td>\n",
       "      <td>46</td>\n",
       "      <td>2022-05-24T12:30:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VC472405221230</td>\n",
       "      <td>VC</td>\n",
       "      <td>47</td>\n",
       "      <td>2022-05-24T12:30:00.000</td>\n",
       "      <td>215</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VC562405221230</td>\n",
       "      <td>VC</td>\n",
       "      <td>56</td>\n",
       "      <td>2022-05-24T12:30:00.000</td>\n",
       "      <td>4.9</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>2022-05-24T12:56:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D1511712201930</td>\n",
       "      <td>D1</td>\n",
       "      <td>51</td>\n",
       "      <td>2020-12-17T19:30:00.000</td>\n",
       "      <td>253</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XG032109201330</td>\n",
       "      <td>XG</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-09-21T13:30:00.000</td>\n",
       "      <td>66</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>2020-09-21T13:50:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XG302109201330</td>\n",
       "      <td>XG</td>\n",
       "      <td>30</td>\n",
       "      <td>2020-09-21T13:30:00.000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XG312109201330</td>\n",
       "      <td>XG</td>\n",
       "      <td>31</td>\n",
       "      <td>2020-09-21T13:30:00.000</td>\n",
       "      <td>83</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XG322109201330</td>\n",
       "      <td>XG</td>\n",
       "      <td>32</td>\n",
       "      <td>2020-09-21T13:30:00.000</td>\n",
       "      <td>23.3</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XG332109201330</td>\n",
       "      <td>XG</td>\n",
       "      <td>33</td>\n",
       "      <td>2020-09-21T13:30:00.000</td>\n",
       "      <td>64</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XG342109201330</td>\n",
       "      <td>XG</td>\n",
       "      <td>34</td>\n",
       "      <td>2020-09-21T13:30:00.000</td>\n",
       "      <td>1002.2</td>\n",
       "      <td>V</td>\n",
       "      <td>SH</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id codi_estacio codi_variable             data_lectura  \\\n",
       "0  VC462405221230           VC            46  2022-05-24T12:30:00.000   \n",
       "1  VC472405221230           VC            47  2022-05-24T12:30:00.000   \n",
       "2  VC562405221230           VC            56  2022-05-24T12:30:00.000   \n",
       "3  D1511712201930           D1            51  2020-12-17T19:30:00.000   \n",
       "4  XG032109201330           XG             3  2020-09-21T13:30:00.000   \n",
       "5  XG302109201330           XG            30  2020-09-21T13:30:00.000   \n",
       "6  XG312109201330           XG            31  2020-09-21T13:30:00.000   \n",
       "7  XG322109201330           XG            32  2020-09-21T13:30:00.000   \n",
       "8  XG332109201330           XG            33  2020-09-21T13:30:00.000   \n",
       "9  XG342109201330           XG            34  2020-09-21T13:30:00.000   \n",
       "\n",
       "  valor_lectura codi_estat codi_base              data_extrem  \n",
       "0             1          V        SH                      NaN  \n",
       "1           215          V        SH                      NaN  \n",
       "2           4.9          V        SH  2022-05-24T12:56:00.000  \n",
       "3           253          V        SH                      NaN  \n",
       "4            66          V        SH  2020-09-21T13:50:00.000  \n",
       "5           0.9          V        SH                      NaN  \n",
       "6            83          V        SH                      NaN  \n",
       "7          23.3          V        SH                      NaN  \n",
       "8            64          V        SH                      NaN  \n",
       "9        1002.2          V        SH                      NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://analisi.transparenciacatalunya.cat/resource/nzvn-apee.json\"\n",
    "df = load_json_from_api(url, chunk_size=10, max_rows=100)\n",
    "logger.info(f\"Loaded {len(df)} rows of data\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "013508f9-c30f-42ca-a533-84d48aaa9918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request.\n\tQuery coordinator error: query.soql.type-mismatch; Type mismatch for op$=, is number; position: Map(row -> 1, column -> 145, line -> \"SELECT `id`, `codi_estacio`, `codi_variable`, `data_lectura`, `data_extrem`, `valor_lectura`, `codi_estat`, `codi_base` WHERE `codi_variable` = 32 ORDER BY `valor_lectura` ASC NULL LAST LIMIT 10\\n                                                                                                                                                ^\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m Socrata(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manalisi.transparenciacatalunya.cat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#results = client.get(\"nzvn-apee\", limit=10, order=\"codi_variable ASC\")\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnzvn-apee\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalor_lectura ASC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcodi_variable=32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert to pandas DataFrame\u001b[39;00m\n\u001b[1;32m      9\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(results)\n",
      "File \u001b[0;32m~/.envs/ub/lib/python3.9/site-packages/sodapy/socrata.py:412\u001b[0m, in \u001b[0;36mSocrata.get\u001b[0;34m(self, dataset_identifier, content_type, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m    410\u001b[0m params \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mclear_empty_values(params)\n\u001b[0;32m--> 412\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.envs/ub/lib/python3.9/site-packages/sodapy/socrata.py:555\u001b[0m, in \u001b[0;36mSocrata._perform_request\u001b[0;34m(self, request_type, resource, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# handle errors\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m202\u001b[39m):\n\u001b[0;32m--> 555\u001b[0m     \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# when responses have no content body (ie. delete, set_permission),\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# simply return the whole response\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext:\n",
      "File \u001b[0;32m~/.envs/ub/lib/python3.9/site-packages/sodapy/utils.py:30\u001b[0m, in \u001b[0;36mraise_for_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m more_info \u001b[38;5;129;01mand\u001b[39;00m more_info\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m!=\u001b[39m response\u001b[38;5;241m.\u001b[39mreason\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m     29\u001b[0m     http_error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(more_info)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request.\n\tQuery coordinator error: query.soql.type-mismatch; Type mismatch for op$=, is number; position: Map(row -> 1, column -> 145, line -> \"SELECT `id`, `codi_estacio`, `codi_variable`, `data_lectura`, `data_extrem`, `valor_lectura`, `codi_estat`, `codi_base` WHERE `codi_variable` = 32 ORDER BY `valor_lectura` ASC NULL LAST LIMIT 10\\n                                                                                                                                                ^\")"
     ]
    }
   ],
   "source": [
    "from sodapy import Socrata\n",
    "\n",
    "client = Socrata(\"analisi.transparenciacatalunya.cat\", None)\n",
    "\n",
    "#results = client.get(\"nzvn-apee\", limit=10, order=\"codi_variable ASC\")\n",
    "results = client.get(\"nzvn-apee\", limit=10, order=\"valor_lectura ASC\", where=\"codi_variable=32\")\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024eab9b-6f9f-4f35-8b6d-3ed4d06e52d1",
   "metadata": {},
   "source": [
    "### Convert data from object to float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8aab2a3-9bf7-4c18-bd9a-4367347ebb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    object\n",
       "B    object\n",
       "C    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with numbers as strings with commas\n",
    "data = {\n",
    "    'A': ['1,00', '2,50', '3,750'],\n",
    "    'B': ['4,20', '5,10', '6,850'],\n",
    "    'C': ['7,00', '8,15', '9,900']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea74a258-155a-48dc-90d3-04bc8f512e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    float64\n",
       "B     object\n",
       "C     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numbers to floats by removing commas\n",
    "df['A'] = df['A'].replace(',', '.', regex=True).astype(float)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee2833e1-3099-4d9e-8442-b6631fcaf70c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    float64\n",
       "B    float64\n",
       "C     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numbers to floats by removing commas\n",
    "df['B'] = df['B'].apply(lambda x: float(x.replace(',', '.')))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6daebe10-79e7-4507-8ae2-4d9548bda131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    float64\n",
       "B    float64\n",
       "C    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['C'] = pd.to_numeric(df['C'].str.replace(',', '.'))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f844c781-17e0-44c3-86a1-0e94b3bcbe6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>4.20</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.50</td>\n",
       "      <td>5.10</td>\n",
       "      <td>8.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.75</td>\n",
       "      <td>6.85</td>\n",
       "      <td>9.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C\n",
       "0  1.00  4.20  7.00\n",
       "1  2.50  5.10  8.15\n",
       "2  3.75  6.85  9.90"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45aff4-d812-44c0-bbc2-86a9a33044b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ub",
   "language": "python",
   "name": "ub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
